"""LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ  
Perplexity Labs API ç‰ˆï¼ˆOpenAI ä¸ä½¿ç”¨ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
  pip install streamlit pandas numpy scikit-learn sentence-transformers requests

â€»APIã‚­ãƒ¼ã¯ .streamlit/secrets.toml ã«ä»¥ä¸‹ã®ã‚ˆã†ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚

[PerplexityAPI]
api_key = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
"""

# â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import pandas as pd
import numpy as np
import datetime
import re
import unicodedata
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# â”€â”€ Streamlit è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ“˜", layout="centered")

# â”€â”€ Embedding ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«: MiniLMï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def load_embedder():
    return SentenceTransformer("all-MiniLM-L6-v2")

embedder = load_embedder()

# â”€â”€ Perplexity API å…±é€šè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PPLX_ENDPOINT = "https://api.perplexity.ai/chat/completions"
PPLX_HEADERS = {
    "Authorization": f"Bearer {st.secrets['PerplexityAPI']['api_key']}",
    "Content-Type": "application/json",
}

# â”€â”€ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
system_prompt = """
ã‚ãªãŸã¯LRADå°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
ã€ŒLRADï¼ˆã‚¨ãƒ«ãƒ©ãƒ‰ï¼‰ã€ã¨ã¯ç†±åˆ†è§£è£…ç½®ï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®ã“ã¨ã§ã€ã“ã‚Œã¯æœ‰æ©Ÿå»ƒæ£„ç‰©ã®å‡¦ç†è£…ç½®ã§ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ã“ã®è£…ç½®ã®æ¤œè¨¼ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦ãã ã•ã„ï¼š
ãƒ»è£…ç½®ã«é–¢é€£ã™ã‚‹ã“ã¨ã®ã¿ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚
ãƒ»é–¢ä¿‚ãªã„è©±é¡Œï¼ˆå¤©æ°—ã€èŠ¸èƒ½ã€ã‚¹ãƒãƒ¼ãƒ„ãªã©ï¼‰ã«ã¯ç­”ãˆãªã„ã§ãã ã•ã„ã€‚
ãƒ»FAQã«ãªã„å ´åˆã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚
"""

# â”€â”€ å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def is_valid_input(text: str) -> bool:
    text = text.strip()
    if not (3 <= len(text) <= 300):
        return False
    non_alpha_ratio = len(re.findall(r"[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]", text)) / len(text)
    if non_alpha_ratio > 0.3:
        return False
    try:
        unicodedata.normalize("NFKC", text).encode("utf-8")
    except UnicodeError:
        return False
    return True

# â”€â”€ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def get_embedding(text: str) -> np.ndarray:
    """returns L2â€‘normalised vector"""
    emb = embedder.encode(text, normalize_embeddings=True)
    return emb

# â”€â”€ FAQï¼ˆåŸ‹ã‚è¾¼ã¿ä»˜ãï¼‰ãƒ­ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_faq(csv_path: str):
    df = pd.read_csv(csv_path)
    df["embedding"] = df["è³ªå•"].apply(get_embedding)
    return df

faq_df = load_faq("faq.csv")

# â”€â”€ é¡ä¼¼è³ªå•æ¤œç´¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_similar_question(user_input: str, faq_df: pd.DataFrame):
    user_vec = get_embedding(user_input)
    faq_vecs = np.stack(faq_df["embedding"].values)
    scores = cosine_similarity([user_vec], faq_vecs)[0]
    idx = scores.argmax()
    return faq_df.iloc[idx]["è³ªå•"], faq_df.iloc[idx]["å›ç­”"]

# â”€â”€ Perplexity API å‘¼ã³å‡ºã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def perplexity_chat(messages: list[dict], model: str = "sonar-small-chat", temperature: float = 1.2) -> str:
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
    }
    resp = requests.post(PPLX_ENDPOINT, headers=PPLX_HEADERS, json=payload, timeout=60)
    if resp.status_code != 200:
        return f"ã‚¨ãƒ©ãƒ¼: Perplexity API ãŒ {resp.status_code} ã‚’è¿”ã—ã¾ã—ãŸ"
    data = resp.json()
    # äº’æ›æ€§å–ã‚Šã®ãŸã‚ choices / output ä¸¡æ–¹ã‚’è€ƒæ…®
    if "choices" in data:
        return data["choices"][0]["message"]["content"].strip()
    if "output" in data:
        try:
            return data["output"][0]["content"][0]["text"].strip()
        except (KeyError, IndexError):
            pass
    return "ã‚¨ãƒ©ãƒ¼: äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã§ã™ã€‚"

# â”€â”€ GPTå¿œç­”ç”Ÿæˆï¼ˆPerplexityï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_response(context_q: str, context_a: str, user_input: str) -> str:
    prompt = (
        "ä»¥ä¸‹ã¯FAQã«åŸºã¥ã„ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ã§ã™ã€‚\n\n"
        f"è³ªå•: {context_q}\nå›ç­”: {context_a}\n\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_input}\n\n"
        "ã“ã‚Œã‚’å‚è€ƒã«ã€ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ãè‡ªç„¶ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"
    )
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt},
    ]
    return perplexity_chat(messages, model="sonar-small-chat", temperature=1.2)

# â”€â”€ ãƒ­ã‚°ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_log(log_data):
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    fname = f"chatlog_{ts}.csv"
    pd.DataFrame(log_data, columns=["ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•", "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å›ç­”"]).to_csv(
        fname, index=False, encoding="utf-8-sig"
    )
    return fname

# â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")
st.caption("â€»ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯FAQã¨AIã‚’ã‚‚ã¨ã«å¿œç­”ã—ã¾ã™ãŒã€ã™ã¹ã¦ã®è³ªå•ã«æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚")

if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šå¤‰æ›´")
    size_option = st.radio("æ–‡å­—ã‚µã‚¤ã‚ºã‚’é¸æŠ", ["å°", "ä¸­", "å¤§"], index=1)

size_map = {"å°": 18, "ä¸­": 22, "å¤§": 30}
font_px = size_map[size_option]

# å‹•çš„ CSS
st.markdown(
    f"""
    <style>
    div.stChatMessage p {{font-size: {font_px}px !important;}}
    h1 {{font-size: {font_px + 10}px !important;}}
    p > small {{font-size: {max(font_px - 4, 10)}px !important;}}
    div.stText, div[data-testid="stMarkdownContainer"] > div p {{font-size: {font_px}px !important;}}
    div.stTextInput > div > input::placeholder {{font-size: {font_px}px !important;}}
    div.stTextInput > div > input {{font-size: {font_px}px !important;}}
    </style>
    """,
    unsafe_allow_html=True,
)

# ãƒ­ã‚°ä¿å­˜ãƒœã‚¿ãƒ³
if st.button("ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜"):
    fname = save_log(st.session_state.chat_log)
    st.success(f"ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {fname}")
    with open(fname, "rb") as f:
        st.download_button("ã“ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=f, file_name=fname, mime="text/csv")

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_area("è³ªå•ã‚’ã©ã†ãï¼š", height=100)
    submitted = st.form_submit_button("é€ä¿¡")

if submitted and user_input:
    if not is_valid_input(user_input):
        st.session_state.chat_log.insert(0, (user_input, "ã‚¨ãƒ©ãƒ¼ï¼šå…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚"))
        st.experimental_rerun()

    with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
        similar_q, similar_a = find_similar_question(user_input, faq_df)
        answer = generate_response(similar_q, similar_a, user_input)

    st.session_state.chat_log.insert(0, (user_input, answer))
    st.experimental_rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for user_msg, bot_msg in st.session_state.chat_log:
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("assistant"):
        st.markdown(bot_msg)
